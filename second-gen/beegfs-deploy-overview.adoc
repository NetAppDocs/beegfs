---
sidebar: sidebar
permalink: beegfs-deploy-overview.html
keywords:
summary:
---

= Overview of deployment
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./media/

[.lead]
Learn how to assemble second-generation NetApp BeeGFS hardware building blocks and deploy the BeeGFS on NetApp shared-disk high availability solution.

The Deploy setion walks through deploying a BeeGFS file system that consists of one base building block including management, metadata, and storage services, a second building block with metadata and storage services, and a third storage only building block.  This demonstrates the full range of recommended configuration “profiles” for NetApp BeeGFS building blocks.

For each deployment the number of metadata and storage or storage only building blocks may vary from what is demonstrated here depending on capacity and performance requirements.

Deploying the solution involves the following high-level tasks:

* Hardware deployment:
** Physical assembly of each building block including racking and cabling hardware
* Software deployment:
** Configure management IPs on block nodes
** Configure BMC IPs on file nodes
** Install a supported operating system and configuring management networking on file nodes
** Set up an Ansible control node
** Define an Ansible inventory describing the desired BeeGFS file system
** Deploy BeeGFS using Ansible

[NOTE]
The deploy prcedures includes several examples where text needs to be copied to a file. Pay close attention to any inline comments denoted by “#” or “//” characters for anything that should or can be modified for a specific deployment. For example:
`beegfs_ha_ntp_server_pools:  # THIS IS AN EXAMPLE OF A COMMENT!
  - "pool 0.pool.ntp.org iburst maxsources 3"
  - "pool 1.pool.ntp.org iburst maxsources 3"`

== Deploying BeeGFS on NetApp using Ansible
  To tell Ansible about the file and block nodes set up in previous sections, you need to build an inventory including hosts, groups, and variables describing the desired BeeGFS file system.

  Sample inventories can be downloaded from https://github.com/netappeseries/beegfs/tree/master/getting_started/[here].

  To actually apply the configuration described by this inventory,  use the various Ansible modules and roles provided in the NetApp E-Series Ansible collections, in particular the https://github.com/netappeseries/beegfs/tree/master/roles/beegfs_ha_7_2[BeeGFS HA 7.2 role^] that deploys the end-to-end solution.

  While in- depth documentation is provided with the role, this topic section describes how to use it specifically to deploy a NetApp Verified Architecture using the second generation BeeGFS building block design.

  [NOTE]
  Although the deploy steps attempt to provide enough detail that prior experience with Ansible is not a prerequisite to deploy the solution, some familiarity with Ansible and related terminology is strongly recommended.

  The building block architecture described by this NetApp Verified Architecture makes this process straightforward, outside of differing host names and management IPs, the only configuration options that change between each building block is whether it should run:

  * BeeGFS management, metadata, and storage services.  The first building block deployed in each filesystem requires this configuration and is sometimes referred to as the base building block.
  * BeeGFS Metadata and Storage services.
  * BeeGFS Storage services. The use of these different configuration profiles for each building block allows the file system to flexibly scale to meet variable performance and capacity requirements using the same underlying hardware platforms and building block design.

== Inventory layout for a BeeGFS HA cluster
This section provides an overview of the Ansible inventory structure used to define a BeeGFS HA cluster.

Anyone with previous Ansible experience should be aware the BeeGFS HA role implements a custom method of discovering which variables (or facts) apply to each host. This is required to simplify building an Ansible inventory that describes resources that can run one multiple servers. 

An Ansible inventory typically consists of three things, the files in `host_vars` and `group_vars` and an `inventory.yml` file that assigns hosts to specific groups (and potentially groups to other groups).

[NOTE]
Don’t create any files with the content in this subsection is intended as an example to help the reader understand the scheme that is used in the following sections.

Although this configuration is predetermined based on the configuration profile, a general understanding of how everything is laid out as an Ansible inventory might be helpful:

....
# BeeGFS HA (High Availability) cluster inventory.
all:
  children:
    # Ansible group representing all block nodes:
    eseries_storage_systems:
      hosts:
        ictad22a01:
        ictad22a02:
        ictad22a03:
        ictad22a04:
        ictad22a05:
        ictad22a06:
    # Ansible group representing all file nodes:
    ha_cluster:
      children:
        meta_01:  # Group representing a metadata service with ID 01.
          hosts:
            file_node_01:  # This service is preferred on the first file node.
            file_node_02:  # And can failover to the second file node.
        meta_02:  # Group representing a metadata service with ID 02.
          hosts:
            file_node_02:  # This service is preferred on the second file node.
            file_node_01: # And can failover to the first file node.
....

For each service,  an additional file is created under `group_vars` describing its configuration.

....
# meta_01 - BeeGFS HA Metadata Resource Group
beegfs_ha_beegfs_meta_conf_resource_group_options:
  connMetaPortTCP: 8015
  connMetaPortUDP: 8015
  tuneBindToNumaZone: 0
floating_ips:
  - i1b: <IP>/<SUBNET_MASK>
  - i4b: <IP>/<SUBNET_MASK>
# Type of BeeGFS service the HA resource group will manage.
beegfs_service: metadata # Choices: management, metadata, storage.
# What block node should be used to create a volume for this service:
beegfs_targets:
  ictad22a01:
    eseries_storage_pool_configuration:
      - name: beegfs_m1_m2_m5_m6
        raid_level: raid1
        criteria_drive_count: 4
        owning_controller: A
        common_volume_configuration:
          segment_size_kb: 128
        volumes:
          - size: 21.25
....

This allows the BeeGFS service, network, and storage configuration for each resource to be defined in a single place. Behind the scenes,  the BeeGFS role handles aggregating the necessary configuration for each file and block node based on this inventory structure.  For more information, see this https://www.netapp.com/blog/accelerate-deployment-of-ha-for-beegfs-with-ansible/[blog post^].

[NOTE]
The BeeGFS numerical and string node ID for each service is automatically configured based on the group name. Thus,  in addition to the general Ansible requirement for group names to be unique, groups representing a BeeGFS service must end in a number that is unique for the type of BeeGFS service the group represents. For example,  meta_01 and stor_01 are allowed, but metadata_01 and meta_01 are not.
