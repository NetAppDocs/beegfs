---
sidebar: sidebar
permalink: beegfs-deploy-hardware-deployment.html
keywords:
summary:
---

= Deploy hardware
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./media/

[.lead]
This section walks through the steps to physically assemble a single building block.  Unless otherwise noted,  these steps are identical for each building block in the cluster regardless of whether it  used to run BeeGFS metadata and storage services or storage services only. Each building block consists of two validated x86 file nodes directly connected using HDR (200Gb) InfiniBand to two NetApp block nodes.

[NOTE]
Because each building block includes two BeeGFS file nodes, a minimum of two building blocks is required to establish quorum in the failover cluster. While it is possible to configure a two-node cluster, there are limitations to this configuration that can prevent a successful failover to occur in some scenarios.  If a two-node cluster is required,  it is also possible to incorporate a third device as a tiebreaker,  though that is not covered in this deployment procedure.

== Rack and cable hardware

Each BeeGFS file node requires four PCIe 4.0 ConnectX-6 dualport Host Channel Adapters (HCAs) configured in InfiniBand mode to be installed in PCIe slots 2, 3, 5, and 6.

Each BeeGFS block node requires a dualport 200Gb Host Interface Card (HIC) be installed in each of its two storage controllers.  The building blocks should be racked so the two BeeGFS file nodes are above the BeeGFS block nodes. This figure shows the correct hardware configurationthe BeeGFS building block (rear view).

image:beegfs-deploy-image2.png[Error: Missing Graphic Image]

[NOTE]
The power supply configuration for production use cases should typically use redundant PSUs.

If needed,  install the drives in each of the BeeGFS block nodes. If the building block will be used to run BeeGFS metadata and storage services and smaller drives are used for metadata volumes, verify they are populated in the outermost drive slots,  as shown in the figure below.  For all building block configurations,  if a drive enclosure is not fully populated, an equal number of drives are populated in slots 0–11 and 12–23 for optimal performance.

image:beegfs-deploy-image3.png[Error: Missing Graphic Image]

Us 1m InfiniBand HDR 200Gb directattach copper cables the file and block nodes togethermatch the topology shown in the figure below.

image:beegfs-deploy-image4.png[Error: Missing Graphic Image]

[NOTE]
The nodes across multiple building blocks never directly connected. Each building block should be treated as a standalone unit and all communication between building blocks occurs through network switches.

Using 2m (or the appropriate length) InfiniBand HDR 200Gb directattach copper cables, the remaining InfiniBand ports on each file node to the InfiniBand switches that  used for the storage network.  If there are redundant InfiniBand switches in use, cable the ports highlighted in light green versus dark green in the following figure to different switches.

image:beegfs-deploy-image5.png[Error: Missing Graphic Image]

As needed,  assemble additional building blocks following the same cabling guidelines.

[NOTE]
The total number of building blocks that can be deployed in a single rack depends on the available power and cooling at each site.
