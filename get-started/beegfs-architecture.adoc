---
sidebar: sidebar
permalink: beegfs-architecture.html
keywords: BeeGFS, NetApp, solution
summary: "NetApp Verified Architectures combine the BeeGFS parallel file system with NetApp EF600 storage systems."
---

= BeeGFS architecture overview
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./media/


[.lead]
The BeeGFS architecture includes core components and general benefits behind its parallel cluster file system.

== Main components
BeeGFS is a parallel file system with an architecture based on the following four main services:

* *Management service.* Registers and monitors all other services.
* *Storage service.* Stores the distributed user file contents known as data chunk files.
* *Metadata service.* Keeps track of the file system layout, directory, and file attributes, and so on.
* *Client service.* Mounts the file system to access the stored data.

As a parallel file system, BeeGFS stripes its files over multiple server nodes to maximize read/write performance and scalability. The server nodes work together to deliver a single file system that can be simultaneously mounted and accessed by other server nodes, commonly known as _clients_. These clients can see and consume the distributed file system similarly to a local file system such as NTFS, XFS, or ext4.

The four main services run on a wide range of supported Linux distributions and communicate via any TCP/IP or RDMA-capable network, including InfiniBand (IB), Omni-Path (OPA), and RDMA over Converged Ethernet (RoCE). The BeeGFS server (management, storage, and metadata) services are user space daemons, while the client is a native kernel module (patchless). All components can be installed or updated without rebooting, and you can run any combination of services on the same node.

image:../media/beegfs-components.png[]

== Benefits
The key benefits of the BeeGFS parallel file system include:

* Optimized for diverse workloads within a single storage namespace.

* Ease of use, straightforward installation, and simple management.

* Reduced client CPU overhead to facilitate network transfers by using remote direct memory access (RDMA) over IB.

* Intelligently distributed file contents and metadata optimized for highly concurrent access.
