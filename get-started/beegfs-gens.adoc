---
sidebar: sidebar
permalink: beegfs-gens.html
keywords: BeeGFS, NetApp, solution
summary: "NetApp Verified Architectures combine the BeeGFS parallel file system with NetApp EF600 storage systems."
---

= Design generations
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./media/


[.lead]
The BeeGFS on NetApp solution is currently in its second generational design.

Both the first and second generation include a base architecture that incorporates a BeeGFS file system and an NVMe EF600 storage system. However, the second generation builds on the first to include these additional benefits:

* Double the performance and capacity while adding only 2U of rack space
* High availability (HA) based on a shared-disk, two-tier hardware design
* External qualification for NVIDIA’s DGX A100 SuperPOD

== Second generational design
The second generation of BeeGFS on NetApp is optimized to meet the performance requirements of demanding workloads including high-performance computing (HPC) and HPC-style machine learning (ML), deep learning (DL) and similar artificial intelligence (AI) techniques. By incorporating a shared-disk high-availability (HA) architecture, the solution also meets the data durability and availability requirements of enterprises and other organizations that cannot afford downtime or data loss as they look for storage that can scale to keep up with their next generation workloads and use cases. This solution has not only been verified by NetApp, but it also passed external qualification as a storage option for the NVIDIA DGX SuperPOD.

=== HPC-style workloads

The second generation of the BeeGFS on NetApp solution provides a flexible and robust storage architecture for demanding high-performance computing (HPC) and HPC-style ML/DL workloads. HPC-style workloads are typically characterized by multiple compute nodes or GPUs (often referred to as clients) all needing to access the same dataset in parallel to facilitate a distributed compute or training job. These datasets are often comprised of large files that should be striped across multiple physical storage nodes to eliminate the traditional hardware bottlenecks that would prevent concurrent access from tens, hundreds, or even thousands of clients to a single file.

The design of parallel file systems like BeeGFS have been proven historically as the preferred storage option for these HPC-style workloads. While traditionally these types of storage requirements were more commonly found in academic and research environments, as the value of data continues to explode, enterprises are increasingly finding themselves with similar requirements. This is driven in no small part by the maturing of various AI techniques and the availability and affordability of hardware accelerators such as GPUs that put advanced AI capabilities in reach of all organizations.

This shift toward HPC-style workloads in the enterprise has introduced high standards around fault tolerance and high availability in addition to the extreme performance expected from parallel file systems. NetApp brings decades of experience building trusted enterprise storage systems, with its E-Series and EF-Series arrays being the most deployed block layer behind various parallel file systems in traditional HPC and media and entertainment environments. It is from this rich history NetApp steps forward to deliver fully supported, next generation parallel file system storage solutions for both traditional and enterprise HPC workloads, including HPC-style ML/DL training and large-large-scale natural language processing (NLP) and natural language understanding (NLU) workloads.


=== Use cases

The second generation of the BeeGFS on NetApp solution applies to the following use cases:

* AI including ML, DL, NLP, and NLU
* HPC including applications accelerated by MPI and other distributed computing techniques
* Application workloads characterized by:
** Reading or writing to files larger than 1GB
** Reading or writing to the same file by multiple clients (10s, 100s, and 1000s)
* Multi-terabyte or multi-petabyte datasets
* Environments that need a single storage namespace optimizable for a mix of large and small files

== First generational design

The first generation of BeeGFS on NetApp was designed for machine learning (ML) and artificial intelligence (AI) workloads using NetApp EF600 NVMe storage systems, the BeeGFS parallel file system, NVIDIA DGX™ A100 systems, and NVIDIA® Mellanox® Quantum™ QM8700 200Gbps IB switches. This design also features 200Gbps InfiniBand (IB) for the storage and compute cluster interconnect fabric to provide customers with a completely IB-based architecture for high-performance workloads.

For more information on the first generation, see link:https://www.netapp.com/pdf.html?item=/media/25445-nva-1156-design.pdf[NetApp EF-Series AI with NVIDIA DGX A100 Systems and BeeGFS^].
